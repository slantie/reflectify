{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6387f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Set, Any, Optional\n",
    "\n",
    "# --- Configuration Constants ---\n",
    "# Folder where uploaded Excel files will be stored.\n",
    "UPLOAD_FOLDER: str = 'uploads'\n",
    "# Allowed file extensions for Excel files.\n",
    "ALLOWED_EXTENSIONS: Set[str] = {'xlsx', 'xls'}\n",
    "\n",
    "# Ensure the upload folder exists.\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "\n",
    "# --- Global Data Mappings and Abbreviations ---\n",
    "\n",
    "# Default path for the matrix Excel file. This can be overridden or dynamically set.\n",
    "# It's good practice to make this configurable rather than hardcoding if it changes often.\n",
    "matrix_file_path: str = os.path.join(UPLOAD_FOLDER, 'matrix.xlsx')\n",
    "\n",
    "# Mapping for various day abbreviations/full names to a consistent format.\n",
    "# This is used to standardize day names extracted from the Excel sheets.\n",
    "DAY_MAPPING: Dict[str, str] = {\n",
    "    'MON': 'Monday', 'MONDAY': 'Monday',\n",
    "    'TUES': 'Tuesday', 'TUESDAY': 'Tuesday',\n",
    "    'WED': 'Wednesday', 'WEDNESDAY': 'Wednesday',\n",
    "    'THUR': 'Thursday', 'THURSDAY': 'Thursday',\n",
    "    'FRI': 'Friday', 'FRIDAY': 'Friday',\n",
    "    'SAT': 'Saturday', 'SATURDAY': 'Saturday'\n",
    "}\n",
    "\n",
    "# Set of known faculty abbreviations.\n",
    "# These are used to identify valid faculty columns in the Excel sheets.\n",
    "faculty_abbreviations: Set[str] = {\n",
    "    'MPB','SJM','ABP','NVP','AJD','JJK','TNG','AA','HMB','RSG','PM','VB','JCK','DC','RP','PJP',\n",
    "    'OP','VMP','HCP','HT','DT','LG','ARB','YV','SVP','PC','SHP','PKP','DJ','RW','NT','KR','AMP',\n",
    "    'TP','MV','SCB','MS','JJP','AVD','SCP','HJP','KV','PS','AP','MNC','BBP','PDN','KRK','SMC',\n",
    "    'BP','AHS','BZ','HPS','JHG','KP','NPC','RKS','RMM','VP'\n",
    "}\n",
    "\n",
    "# Set of known subject abbreviations.\n",
    "# These are used to validate subject codes extracted from the subject strings.\n",
    "subject_abbreviations: Set[str] = {\n",
    "    'EM1','EP','FOP','ECE','EG','ES','EM2','BEEE','OOPC','FME','Workshop','NN','IR','WDM','PDA',\n",
    "    'BCPS','IICT','PD','EI','DM','DSA','DE','ITW','DBMS','POM','PSNM','COA','OS''OOPJ','SE','MP',\n",
    "    'TOC','DAA','CN','AJP','ACA','DNET','OT','CG','AI','PYP','CNS','AP','IOP','ES','AA','ML','SC',\n",
    "    'ITC','AOS','IOT','GT','ACN','CD','CS','HPC','CNT','NLP','BT','DS','QC','IP','NGN','BDA','ASN',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345bbd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_excel_cell(value: Any) -> Optional[Any]:\n",
    "    \"\"\"\n",
    "    Cleans a cell value by stripping whitespace from strings and converting\n",
    "    empty strings or whitespace-only strings to None.\n",
    "\n",
    "    Args:\n",
    "        value (Any): The raw value from an Excel cell.\n",
    "\n",
    "    Returns:\n",
    "        Optional[Any]: The cleaned value, or None if the original was None,\n",
    "                       an empty string, or a whitespace-only string.\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, str):\n",
    "        cleaned_str = value.strip()\n",
    "        return cleaned_str if cleaned_str != '' else None\n",
    "    return value\n",
    "\n",
    "def extract_sheet_data(workbook: openpyxl.workbook.workbook.Workbook, sheet_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes a single sheet from an OpenPyXL workbook to extract tabular data.\n",
    "    \n",
    "    This function handles merged cells by propagating their values and dynamically\n",
    "    identifies the header row and the last meaningful data column.\n",
    "    It also ensures that empty or whitespace-only cells are treated as None/NaN.\n",
    "\n",
    "    Args:\n",
    "        workbook (openpyxl.workbook.workbook.Workbook): The OpenPyXL workbook object.\n",
    "        sheet_name (str): The name of the sheet to process within the workbook.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A pandas DataFrame containing the cleaned tabular data,\n",
    "                      or an empty DataFrame if the 'SLOT' header is not found\n",
    "                      or no meaningful data columns are present.\n",
    "    \"\"\"\n",
    "    sheet = workbook[sheet_name]\n",
    "    merged_ranges = sheet.merged_cells.ranges\n",
    "    \n",
    "    # Create a new in-memory workbook and sheet to copy data into.\n",
    "    # This is done to \"unmerge\" cells by copying their values to all cells\n",
    "    # within their original merged range, making data extraction easier.\n",
    "    new_workbook = openpyxl.Workbook()\n",
    "    new_sheet = new_workbook.active\n",
    "\n",
    "    # Copy all cell data to the new sheet, cleaning values during transfer.\n",
    "    for row in sheet.rows:\n",
    "        for cell in row:\n",
    "            cleaned_value = clean_excel_cell(cell.value)\n",
    "            new_sheet.cell(row=cell.row, column=cell.column, value=cleaned_value)\n",
    "    \n",
    "    # Propagate values for merged cells in the new sheet.\n",
    "    for merged_range in merged_ranges:\n",
    "        # Get the cleaned value from the top-left cell of the original merged range.\n",
    "        value_to_propagate = clean_excel_cell(sheet.cell(merged_range.min_row, merged_range.min_col).value)\n",
    "        \n",
    "        # Fill all cells within the merged range in the new_sheet with this value.\n",
    "        for row_index in range(merged_range.min_row, merged_range.max_row + 1):\n",
    "            for col_index in range(merged_range.min_col, merged_range.max_col + 1):\n",
    "                new_sheet.cell(row=row_index, column=col_index, value=value_to_propagate)\n",
    "    \n",
    "    # Convert the processed sheet to a pandas DataFrame.\n",
    "    # Empty cells (None) will be converted to NaN by pandas.\n",
    "    data_frame = pd.DataFrame(new_sheet.values)\n",
    "\n",
    "    # --- Dynamic Header Row Detection ---\n",
    "    # Attempt to find the header row by looking for 'SLOT' in the second column (index 1).\n",
    "    try:\n",
    "        # Convert the second column to string type to ensure robust comparison,\n",
    "        # as it might contain mixed data types.\n",
    "        header_index = data_frame[data_frame.iloc[:, 1].astype(str) == 'SLOT'].index[0]\n",
    "    except IndexError:\n",
    "        print(f\"Warning: 'SLOT' not found in the second column of sheet '{sheet_name}'. Returning empty DataFrame.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    header_row_values = data_frame.iloc[header_index]\n",
    "    \n",
    "    # --- Dynamically Trim Columns based on Header Row ---\n",
    "    # Find the first column in the header row that is NaN/None.\n",
    "    # This indicates the boundary where meaningful data columns end.\n",
    "    first_unwanted_col_index = -1\n",
    "    for i, col_value in enumerate(header_row_values):\n",
    "        if pd.isna(col_value):\n",
    "            first_unwanted_col_index = i\n",
    "            break\n",
    "            \n",
    "    # If an unwanted column was found, slice the DataFrame to keep only meaningful columns.\n",
    "    if first_unwanted_col_index != -1:\n",
    "        data_frame = data_frame.iloc[:, :first_unwanted_col_index]\n",
    "    \n",
    "    # Set the DataFrame columns using the identified header row values.\n",
    "    # Slice header_row_values to match the actual number of columns in the trimmed DataFrame.\n",
    "    data_frame.columns = header_row_values.iloc[:data_frame.shape[1]]\n",
    "    \n",
    "    # Remove the header row and all rows above it, then reset the index.\n",
    "    data_frame = data_frame.iloc[header_index + 1:].reset_index(drop=True)\n",
    "    \n",
    "    # --- Final Cleanup - Drop entirely empty rows ---\n",
    "    # Replace any remaining empty strings with NaN (a safeguard, as clean_excel_cell should handle most).\n",
    "    data_frame.replace('', np.nan, inplace=True)\n",
    "    # Drop rows where all values are NaN.\n",
    "    data_frame.dropna(how='all', inplace=True)\n",
    "    \n",
    "    return data_frame\n",
    "\n",
    "def extract_subject_details(subject_string: str, subject_abbreviations: Set[str]) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Parses a raw subject string (e.g., \"SUB1 5A3/B3\") into its components.\n",
    "\n",
    "    It extracts the subject code, semester, and a list of division-batch objects.\n",
    "    This function assumes the format: \"SUBJECT_CODE [SEMESTER][DIVISIONS][BATCH]\".\n",
    "    It filters out 'TUT' (tutorial) entries and validates the subject_code\n",
    "    against a set of known subject abbreviations.\n",
    "\n",
    "    Args:\n",
    "        subject_string (str): The raw subject string from the processed DataFrame cell.\n",
    "        subject_abbreviations (Set[str]): A set of strings containing all valid\n",
    "                                          subject codes to consider.\n",
    "\n",
    "    Returns:\n",
    "        Optional[Dict[str, Any]]: A dictionary containing 'subject_code', 'semester', and\n",
    "                                  'division_batches' if parsing is successful. Returns None\n",
    "                                  if the input is invalid, a tutorial, does not match the\n",
    "                                  expected format, or if the subject_code is not in the\n",
    "                                  provided `subject_abbreviations` set.\n",
    "                                  Example output:\n",
    "                                  {\n",
    "                                      'subject_code': 'OT',\n",
    "                                      'semester': 5,\n",
    "                                      'division_batches': [{'division': 'A', 'batch': '3'}, {'division': 'B', 'batch': '3'}]\n",
    "                                  }\n",
    "    \"\"\"\n",
    "    # Initial validation: check if input is a valid non-empty string and not a tutorial.\n",
    "    if not isinstance(subject_string, str) or not subject_string.strip() or 'TUT' in subject_string.upper():\n",
    "        return None\n",
    "\n",
    "    # Split the string into parts based on whitespace.\n",
    "    # Expected format: ['SUBJECT_CODE', 'CLASS_INFO']\n",
    "    # maxsplit=1 ensures only the first space splits, handling subject codes with spaces if any.\n",
    "    parts = subject_string.strip().split(maxsplit=1)\n",
    "\n",
    "    # Ensure there are at least two parts (subject code and class info).\n",
    "    if len(parts) < 2:\n",
    "        return None\n",
    "\n",
    "    subject_code = parts[0]\n",
    "\n",
    "    # Validate subject_code against known abbreviations.\n",
    "    if subject_code not in subject_abbreviations:\n",
    "        return None\n",
    "\n",
    "    class_info = parts[1] # This part contains semester, divisions, and batch (e.g., \"5A3/B3\")\n",
    "\n",
    "    semester: Optional[int] = None\n",
    "    division_batches: List[Dict[str, Optional[str]]] = []\n",
    "\n",
    "    # --- Extract Semester ---\n",
    "    # Use regex to find the leading digit(s) for the semester.\n",
    "    semester_match = re.match(r'^(\\d+)', class_info)\n",
    "    if semester_match:\n",
    "        semester = int(semester_match.group(1))\n",
    "        # Remove the semester prefix from class_info for subsequent parsing.\n",
    "        class_info_without_semester = class_info[semester_match.end():]\n",
    "    else:\n",
    "        # If no semester digit is found at the beginning, the format is unexpected.\n",
    "        return None\n",
    "\n",
    "    # --- Process Divisions and Batch ---\n",
    "    # Handle the special 'ALL' division case.\n",
    "    if 'ALL' in class_info_without_semester.upper():\n",
    "        division_batches = [{'division': 'ALL', 'batch': None}]\n",
    "    else:\n",
    "        # Split the remaining class_info by '/' to get individual division segments\n",
    "        # (e.g., \"A3\", \"B3\", \"A\", \"B*\").\n",
    "        division_segments = class_info_without_semester.split('/')\n",
    "\n",
    "        for segment in division_segments:\n",
    "            # Extract only alphabetic characters for the division letter, preserving case.\n",
    "            division_letter = ''.join(char for char in segment if char.isalpha()).strip()\n",
    "\n",
    "            batch_value: Optional[str] = None\n",
    "            # Regex looks for one or more digits followed by an optional asterisk at the end.\n",
    "            batch_match = re.search(r'(\\d+\\*?)$', segment)\n",
    "            if batch_match:\n",
    "                batch_value = batch_match.group(1)\n",
    "\n",
    "            if division_letter: # Only add if a valid division letter was found.\n",
    "                division_batches.append({'division': division_letter, 'batch': batch_value})\n",
    "\n",
    "    # Ensure division_batches are unique (based on division and batch combined)\n",
    "    # and sorted for consistent output, unless 'ALL' is the only entry.\n",
    "    if not division_batches or division_batches[0].get('division') != 'ALL':\n",
    "        unique_division_batches: List[Dict[str, Optional[str]]] = []\n",
    "        seen_tuples: Set[tuple] = set()\n",
    "        for item in division_batches:\n",
    "            item_tuple = (item['division'], item['batch'])\n",
    "            if item_tuple not in seen_tuples:\n",
    "                unique_division_batches.append(item)\n",
    "                seen_tuples.add(item_tuple)\n",
    "\n",
    "        # Sort by division letter, then by batch (None values sorted last).\n",
    "        division_batches = sorted(unique_division_batches, key=lambda x: (x['division'], x['batch'] if x['batch'] is not None else ''))\n",
    "\n",
    "    return {\n",
    "        'subject_code': subject_code,\n",
    "        'semester': semester,\n",
    "        'division_batches': division_batches,\n",
    "    }\n",
    "\n",
    "def build_faculty_schedules(processed_data_frame: pd.DataFrame, known_faculty_abbreviations: Set[str], subject_abbreviations: Set[str]) -> Dict[str, Dict[str, List[Dict[str, Any]]]]:\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping each faculty member to their weekly schedule.\n",
    "\n",
    "    This optimized version now includes the parsed subject information directly\n",
    "    within each session entry, avoiding redundant parsing later.\n",
    "\n",
    "    Args:\n",
    "        processed_data_frame (pd.DataFrame): The DataFrame processed by `extract_sheet_data`.\n",
    "        known_faculty_abbreviations (Set[str]): A set of valid faculty abbreviations.\n",
    "        subject_abbreviations (Set[str]): A set of valid subject abbreviations to use\n",
    "                                     when parsing subject strings.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict[str, List[Dict[str, Any]]]]: A dictionary where keys are faculty names\n",
    "                                                    and values are dictionaries containing their\n",
    "                                                    schedule for each day of the week.\n",
    "    \"\"\"\n",
    "    faculty_master: Dict[str, Dict[str, List[Dict[str, Any]]]] = {}\n",
    "\n",
    "    # Identify actual faculty names from the DataFrame columns, excluding the first two\n",
    "    # (assumed to be 'Day' and 'SLOT') and filtering by known abbreviations.\n",
    "    faculty_names = [\n",
    "        col for col in processed_data_frame.columns[2:]\n",
    "        if col in known_faculty_abbreviations\n",
    "    ]\n",
    "\n",
    "    # Initialize an empty schedule for each identified faculty member for all days.\n",
    "    for faculty in faculty_names:\n",
    "        faculty_master[faculty] = {\n",
    "            'Monday': [], 'Tuesday': [], 'Wednesday': [],\n",
    "            'Thursday': [], 'Friday': [], 'Saturday': []\n",
    "        }\n",
    "\n",
    "    # Process schedules for each identified faculty member.\n",
    "    for faculty in faculty_names:\n",
    "        faculty_column = processed_data_frame[faculty] # Get the series for the current faculty's schedule\n",
    "\n",
    "        row_index = 0 # Correctly initialized loop variable\n",
    "        while row_index < len(faculty_column):\n",
    "            raw_day_value = processed_data_frame.iloc[row_index, 0]\n",
    "            raw_time_slot_start = processed_data_frame.iloc[row_index, 1]\n",
    "            raw_subject_string = faculty_column.iloc[row_index]\n",
    "\n",
    "            # Process day value.\n",
    "            day_string = str(raw_day_value).strip().upper()\n",
    "            day = DAY_MAPPING.get(day_string)\n",
    "\n",
    "            # Check if cell contains valid data and a valid day was mapped.\n",
    "            if pd.notna(raw_subject_string) and raw_subject_string != '' and day is not None:\n",
    "                # Convert time_slot_start to int, with error handling.\n",
    "                try:\n",
    "                    time_slot_start = int(raw_time_slot_start)\n",
    "                except (ValueError, TypeError):\n",
    "                    print(f\"Warning: Time slot '{raw_time_slot_start}' for subject '{raw_subject_string}' \"\n",
    "                          f\"for faculty '{faculty}' on {day} is not a valid integer. Skipping entry.\")\n",
    "                    row_index += 1\n",
    "                    continue\n",
    "\n",
    "                current_subject_value = raw_subject_string\n",
    "                block_start_row_index = row_index\n",
    "\n",
    "                # Find the end of the contiguous block for the current subject.\n",
    "                block_end_row_index = row_index # Correct variable name\n",
    "                while (block_end_row_index + 1 < len(faculty_column) and\n",
    "                       faculty_column.iloc[block_end_row_index + 1] == current_subject_value and # Correct variable name\n",
    "                       str(processed_data_frame.iloc[block_end_row_index + 1, 0]).strip().upper() == day_string): # Correct variable name\n",
    "                    block_end_row_index += 1 # Correct variable name\n",
    "\n",
    "                # Calculate the length of the contiguous block in terms of rows/slots.\n",
    "                block_length = (block_end_row_index - block_start_row_index) + 1\n",
    "\n",
    "                # Determine activity type based on fixed slot allocation rules.\n",
    "                activity_type: str\n",
    "                if block_length == 2:\n",
    "                    activity_type = 'Lab'\n",
    "                elif block_length == 1:\n",
    "                    activity_type = 'Lecture'\n",
    "                else:\n",
    "                    activity_type = 'Unknown'\n",
    "                    print(f\"Warning: Unexpected block length ({block_length}) for subject '{current_subject_value}' \"\n",
    "                          f\"for faculty '{faculty}' on {day} at slot {time_slot_start}. Classified as '{activity_type}'.\")\n",
    "\n",
    "                # Store the raw subject string and its parsed information.\n",
    "                schedule_entry = {\n",
    "                    'subject_string': current_subject_value,\n",
    "                    'type': activity_type,\n",
    "                    'time_slot': time_slot_start,\n",
    "                    # Pass subject_abbreviations to extract_subject_details\n",
    "                    'parsed_subject_info': extract_subject_details(current_subject_value, subject_abbreviations)\n",
    "                }\n",
    "\n",
    "                faculty_master[faculty][day].append(schedule_entry)\n",
    "\n",
    "                # Advance row_index to the end of the processed block to avoid re-processing.\n",
    "                row_index = block_end_row_index + 1\n",
    "            else:\n",
    "                # If the cell is empty, invalid, or day mapping failed, move to the next row.\n",
    "                row_index += 1\n",
    "\n",
    "    return faculty_master\n",
    "\n",
    "def standardize_time_slots(data_frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Formats the 'Time_Slot' column for 'Lab' entries in a DataFrame.\n",
    "    \n",
    "    For 'Lab' entries, it converts the single starting time slot (e.g., 3)\n",
    "    into a two-slot range string (e.g., \"3-4\"). Lecture time slots remain as is.\n",
    "    The DataFrame is then sorted.\n",
    "\n",
    "    Args:\n",
    "        data_frame (pd.DataFrame): The DataFrame containing schedule entries.\n",
    "                           Expected columns include 'Type' and 'Time_Slot'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with 'Time_Slot' formatted for labs,\n",
    "                      and sorted by 'Day', 'Time_Slot', and 'Batch'.\n",
    "    \"\"\"\n",
    "    df_copy = data_frame.copy() \n",
    "\n",
    "    # Explicitly cast 'Time_Slot' to object dtype to allow mixed types (int and str)\n",
    "    # before applying string formatting. This resolves the FutureWarning.\n",
    "    df_copy['Time_Slot'] = df_copy['Time_Slot'].astype(object)\n",
    "\n",
    "    lab_mask = df_copy['Type'] == 'Lab'\n",
    "    df_copy.loc[lab_mask, 'Time_Slot'] = df_copy.loc[lab_mask, 'Time_Slot'].apply(\n",
    "        lambda x: f\"{int(x)}-{int(x)+1}\" if pd.notna(x) else x\n",
    "    )\n",
    "    \n",
    "    def get_time_slot_sort_value(slot: Any) -> Any:\n",
    "        \"\"\"Helper function to extract a sortable value from time slot (int or 'start-end' string).\"\"\"\n",
    "        if isinstance(slot, str) and '-' in slot:\n",
    "            try:\n",
    "                # For ranges like \"3-4\", sort by the starting number.\n",
    "                return int(slot.split('-')[0])\n",
    "            except ValueError:\n",
    "                # Handle cases where string is not a valid range (e.g., \"invalid-slot\"), sort at end.\n",
    "                return float('inf') \n",
    "        elif pd.isna(slot):\n",
    "            # Put NaN values at the end of the sort order.\n",
    "            return float('inf')\n",
    "        try:\n",
    "            # For single integer slots.\n",
    "            return int(slot)\n",
    "        except (ValueError, TypeError):\n",
    "            # Handle non-numeric or unconvertible slots, sort at end.\n",
    "            return float('inf')\n",
    "\n",
    "    # Sort the DataFrame.\n",
    "    # The 'Time_Slot' column needs a custom key because it will contain mixed types (int and str).\n",
    "    # 'Batch' might contain None, so it's converted to string for consistent sorting.\n",
    "    return df_copy.sort_values(\n",
    "        by=['Day', 'Time_Slot', 'Batch'],\n",
    "        key=lambda col: col.apply(get_time_slot_sort_value) if col.name == 'Time_Slot' else col.astype(str),\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "def generate_class_schedules(faculty_schedules: Dict[str, Dict[str, List[Dict[str, Any]]]]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Creates individual timetable DataFrames for each class division.\n",
    "\n",
    "    It processes the consolidated faculty schedules, extracts subject details,\n",
    "    and assigns sessions to the relevant divisions (including 'ALL' divisions).\n",
    "    This optimized version uses pre-parsed subject information stored within\n",
    "    the faculty schedules.\n",
    "\n",
    "    Args:\n",
    "        faculty_schedules (Dict[str, Dict[str, List[Dict[str, Any]]]]): A dictionary of\n",
    "                                                                         consolidated faculty schedules,\n",
    "                                                                         as returned by `process_all_timetables`.\n",
    "                                                                         Each session entry is expected to\n",
    "                                                                         contain a 'parsed_subject_info' key.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, pd.DataFrame]: A dictionary where keys are division identifiers\n",
    "                                 (e.g., \"5A\", \"6B\") and values are pandas DataFrames\n",
    "                                 representing the timetable for that division.\n",
    "                                 The DataFrames are formatted and sorted by\n",
    "                                 `standardize_time_slots`.\n",
    "    \"\"\"\n",
    "    division_tables: Dict[str, List[Dict[str, Any]]] = {}\n",
    "    semester_divisions: Dict[int, Set[str]] = {} # To store all unique divisions for each semester (for 'ALL' cases)\n",
    "\n",
    "    # --- First Pass: Collect all unique divisions per semester ---\n",
    "    # This pass is crucial for correctly expanding 'ALL' entries later.\n",
    "    for faculty_name, faculty_schedule_by_day in faculty_schedules.items():\n",
    "        for day, sessions in faculty_schedule_by_day.items():\n",
    "            for session_entry in sessions:\n",
    "                # Retrieve pre-parsed subject info, which should be available\n",
    "                # from the `build_faculty_schedules` function.\n",
    "                parsed_subject_info = session_entry.get('parsed_subject_info')\n",
    "\n",
    "                # Only proceed if parsing was successful and semester information is present.\n",
    "                if parsed_subject_info and parsed_subject_info['semester'] is not None:\n",
    "                    semester = parsed_subject_info['semester']\n",
    "                    \n",
    "                    # Initialize the set for the current semester if it doesn't exist.\n",
    "                    if semester not in semester_divisions:\n",
    "                        semester_divisions[semester] = set()\n",
    "                    \n",
    "                    # Iterate through the division_batches to collect individual divisions.\n",
    "                    # We only add specific divisions, not the 'ALL' placeholder itself.\n",
    "                    for db_entry in parsed_subject_info.get('division_batches', []):\n",
    "                        division_letter = db_entry.get('division')\n",
    "                        if division_letter and division_letter != 'ALL':\n",
    "                            semester_divisions[semester].add(division_letter)\n",
    "    \n",
    "    # --- Second Pass: Populate division tables ---\n",
    "    # Iterate through each faculty's consolidated schedule to assign sessions to divisions.\n",
    "    for faculty_name, faculty_schedule_by_day in faculty_schedules.items():\n",
    "        for day, sessions in faculty_schedule_by_day.items():\n",
    "            for session_entry in sessions:\n",
    "                # Retrieve pre-parsed subject info for the current session.\n",
    "                parsed_subject_info = session_entry.get('parsed_subject_info')\n",
    "                \n",
    "                # Only process if subject parsing was successful and semester is valid.\n",
    "                if parsed_subject_info and parsed_subject_info['semester'] is not None:\n",
    "                    semester = parsed_subject_info['semester']\n",
    "                    target_division_batch_entries: List[Dict[str, Optional[str]]] = []\n",
    "                    \n",
    "                    # Determine the target divisions/batches for the current session.\n",
    "                    session_division_batches = parsed_subject_info.get('division_batches', [])\n",
    "\n",
    "                    # Check if the first entry indicates 'ALL' divisions.\n",
    "                    if session_division_batches and session_division_batches[0].get('division') == 'ALL':\n",
    "                        # If 'ALL' is specified, expand to all unique divisions known for this semester.\n",
    "                        if semester in semester_divisions:\n",
    "                            # Sort divisions for consistent output order.\n",
    "                            for div in sorted(list(semester_divisions[semester])):\n",
    "                                # For 'ALL' subjects, the batch is typically not specific to a sub-division.\n",
    "                                target_division_batch_entries.append({'division': div, 'batch': None})\n",
    "                    else:\n",
    "                        # Otherwise, use the specific division-batch combinations parsed from the subject string.\n",
    "                        target_division_batch_entries = session_division_batches\n",
    "                    \n",
    "                    # Add the session entry to each relevant division's timetable.\n",
    "                    for db_entry in target_division_batch_entries:\n",
    "                        division = db_entry.get('division')\n",
    "                        batch = db_entry.get('batch') # Get the batch specific to this division entry.\n",
    "                        \n",
    "                        if division: # Ensure division is not None or empty\n",
    "                            # Construct the unique key for the division table (e.g., \"5A\", \"6B\").\n",
    "                            division_key = f\"{semester}{division}\"\n",
    "                            \n",
    "                            # Initialize the list for this division key if it doesn't exist.\n",
    "                            if division_key not in division_tables:\n",
    "                                division_tables[division_key] = []\n",
    "                            \n",
    "                            # Create the entry for the division's timetable.\n",
    "                            entry = {\n",
    "                                'Subject': parsed_subject_info.get('subject_code'),\n",
    "                                'Type': session_entry.get('type'), # Use type directly from faculty_schedules.\n",
    "                                'Batch': batch if batch is not None else '-', # Use specific batch, or '-' if None.\n",
    "                                'Day': day,\n",
    "                                'Time_Slot': session_entry.get('time_slot'), # Use the single time_slot.\n",
    "                                'Faculty': faculty_name\n",
    "                            }\n",
    "                            \n",
    "                            division_tables[division_key].append(entry)\n",
    "    \n",
    "    # --- Convert lists of entries to DataFrames and apply final formatting ---\n",
    "    final_division_dataframes: Dict[str, pd.DataFrame] = {}\n",
    "    for division_key, entries_list in division_tables.items():\n",
    "        if entries_list: # Only create DataFrame if there are entries.\n",
    "            data_frame = pd.DataFrame(entries_list)\n",
    "            # Apply standardize_time_slots to format time slots and sort the DataFrame.\n",
    "            final_division_dataframes[division_key] = standardize_time_slots(data_frame)\n",
    "        else:\n",
    "            # If no entries for a division, return an empty DataFrame with expected columns.\n",
    "            final_division_dataframes[division_key] = pd.DataFrame(columns=['Subject', 'Type', 'Batch', 'Day', 'Time_Slot', 'Faculty'])\n",
    "    \n",
    "    return final_division_dataframes\n",
    "\n",
    "def process_all_timetables(matrix_file_path: str, faculties: Set[str], subjects: Set[str]) -> Dict[str, Dict[str, List[Dict[str, Any]]]]:\n",
    "    \"\"\"\n",
    "    Loads an Excel workbook, processes each sheet, and consolidates\n",
    "    faculty schedules from all sheets into a single dictionary.\n",
    "\n",
    "    Args:\n",
    "        matrix_file_path (str): The path to the Excel file containing timetable data.\n",
    "        faculties (Set[str]): A set of strings containing all valid\n",
    "                               faculty abbreviations to consider as columns.\n",
    "        subjects (Set[str]): A set of strings containing all valid\n",
    "                             subject abbreviations for parsing.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict[str, List[Dict[str, Any]]]]: A consolidated dictionary of all faculty schedules\n",
    "                                                    across all sheets, with entries sorted by time slot\n",
    "                                                    for each day. Returns an empty dictionary if the\n",
    "                                                    file is not found or an error occurs during loading.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        workbook = openpyxl.load_workbook(matrix_file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{matrix_file_path}' was not found.\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading workbook '{matrix_file_path}': {e}\")\n",
    "        return {}\n",
    "\n",
    "    all_faculty_schedules: Dict[str, Dict[str, List[Dict[str, Any]]]] = {}\n",
    "\n",
    "    # Iterate through each sheet in the workbook.\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        print(f\"Processing sheet: {sheet_name}\")\n",
    "        \n",
    "        # Process the current sheet into a cleaned pandas DataFrame.\n",
    "        # This function (extract_sheet_data) is assumed to be defined elsewhere.\n",
    "        processed_data_frame = extract_sheet_data(workbook, sheet_name)\n",
    "        \n",
    "        # Only proceed if the processed DataFrame contains data.\n",
    "        if not processed_data_frame.empty:\n",
    "            # Create a schedule dictionary for the current sheet.\n",
    "            # This function (build_faculty_schedules) is assumed to be defined elsewhere.\n",
    "            # It now requires both faculty and subject abbreviations.\n",
    "            sheet_schedules = build_faculty_schedules(\n",
    "                processed_data_frame, faculties, subjects\n",
    "            )\n",
    "            \n",
    "            # Merge schedules from the current sheet into the overall consolidated schedules.\n",
    "            for faculty_name, schedule_by_day in sheet_schedules.items():\n",
    "                if faculty_name not in all_faculty_schedules:\n",
    "                    # If the faculty is encountered for the first time, add their entire schedule.\n",
    "                    all_faculty_schedules[faculty_name] = schedule_by_day\n",
    "                else:\n",
    "                    # If the faculty already exists, extend their daily schedules with new sessions.\n",
    "                    for day_name in schedule_by_day:\n",
    "                        all_faculty_schedules[faculty_name][day_name].extend(schedule_by_day[day_name])\n",
    "        else:\n",
    "            print(f\"Skipping sheet '{sheet_name}' due to empty or invalid data.\")\n",
    "\n",
    "    # --- Post-processing: Sort schedule entries by time_slot for each faculty and day ---\n",
    "    # This ensures a consistent and chronologically ordered output for each faculty's daily schedule.\n",
    "    for faculty_name, schedule_by_day in all_faculty_schedules.items():\n",
    "        for day_name, entries in schedule_by_day.items():\n",
    "            # Only attempt to sort if there are entries and the 'time_slot' key is present.\n",
    "            if entries and 'time_slot' in entries[0]:\n",
    "                all_faculty_schedules[faculty_name][day_name] = sorted(entries, key=lambda x: x['time_slot'])\n",
    "            # If 'time_slot' is not consistently present (e.g., due to 'Unknown' types),\n",
    "            # or if the list is empty, no sorting is applied to avoid errors.\n",
    "            \n",
    "    return all_faculty_schedules\n",
    "\n",
    "def get_division_course_catalog(division_tables: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Creates condensed timetable DataFrames for each class division.\n",
    "\n",
    "    This function takes the detailed division timetables and removes\n",
    "    time-related information ('Time_Slot', 'Day') to provide a unique\n",
    "    list of subjects, their types, batches, and associated faculty for\n",
    "    each division.\n",
    "\n",
    "    Args:\n",
    "        division_tables (Dict[str, pd.DataFrame]): A dictionary where keys are division identifiers\n",
    "                                                   (e.g., \"5A\", \"6B\") and values are pandas DataFrames\n",
    "                                                   representing the detailed timetable for that division.\n",
    "                                                   These DataFrames are expected to have columns like\n",
    "                                                   'Subject', 'Type', 'Batch', 'Day', 'Time_Slot', 'Faculty'.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, pd.DataFrame]: A dictionary where keys are division identifiers\n",
    "                                 and values are pandas DataFrames representing the\n",
    "                                 condensed timetable for that division. These DataFrames\n",
    "                                 will contain 'Subject', 'Type', 'Batch', and 'Faculty'\n",
    "                                 columns, with duplicate entries removed and sorted.\n",
    "    \"\"\"\n",
    "    condensed_tables: Dict[str, pd.DataFrame] = {}\n",
    "    \n",
    "    # Iterate through each division's detailed timetable DataFrame.\n",
    "    for division_key, data_frame in division_tables.items():\n",
    "        # --- Step 1: Drop time-related columns ---\n",
    "        # Create a new DataFrame by dropping the 'Time_Slot' and 'Day' columns.\n",
    "        # This removes the temporal information, making the table \"condensed\".\n",
    "        # `axis=1` specifies that columns should be dropped.\n",
    "        # `errors='ignore'` prevents an error if 'Time_Slot' or 'Day' columns are already missing.\n",
    "        condensed_df = data_frame.drop(['Time_Slot', 'Day'], axis=1, errors='ignore')\n",
    "        \n",
    "        # --- Step 2: Remove duplicate entries ---\n",
    "        # After dropping 'Time_Slot' and 'Day', multiple rows might become identical\n",
    "        # (e.g., if a subject is taught on different days or at different times).\n",
    "        # `drop_duplicates()` ensures that each unique combination of 'Subject',\n",
    "        # 'Type', 'Batch', and 'Faculty' appears only once.\n",
    "        condensed_df = condensed_df.drop_duplicates()\n",
    "        \n",
    "        # --- Step 3: Sort for better readability ---\n",
    "        # Sort the condensed DataFrame by 'Subject' first, then by 'Batch'.\n",
    "        # This organizes the output logically for easier review.\n",
    "        # `reset_index(drop=True)` creates a new default integer index after sorting.\n",
    "        # The `key` argument is used for 'Batch' to ensure consistent sorting\n",
    "        # even if 'Batch' contains mixed types (e.g., '1', '2', '-', None).\n",
    "        condensed_df = condensed_df.sort_values(\n",
    "            by=['Subject', 'Batch'],\n",
    "            key=lambda col: col.astype(str) if col.name == 'Batch' else col,\n",
    "            ignore_index=True\n",
    "        )\n",
    "        \n",
    "        # --- Step 4: Store the condensed DataFrame ---\n",
    "        # Add the processed (condensed and unique) DataFrame to the result dictionary\n",
    "        # using the original division key.\n",
    "        condensed_tables[division_key] = condensed_df\n",
    "    \n",
    "    return condensed_tables\n",
    "\n",
    "def build_hierarchical_schedule(\n",
    "    condensed_division_tables: Dict[str, pd.DataFrame],\n",
    "    department: str,\n",
    "    college: str = \"LDRP-ITR\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Creates a final hierarchical dictionary consolidating all timetable information\n",
    "    grouped by college, department, semester, division, and subject.\n",
    "\n",
    "    This function processes the condensed timetable DataFrames to extract\n",
    "    designated faculty for lectures and labs (per batch).\n",
    "\n",
    "    Args:\n",
    "        condensed_division_tables (Dict[str, pd.DataFrame]): A dictionary where keys are\n",
    "                                                             division identifiers (e.g., \"5A\", \"6B\")\n",
    "                                                             and values are pandas DataFrames\n",
    "                                                             representing the condensed timetable\n",
    "                                                             for that division. These DataFrames\n",
    "                                                             are expected to have 'Subject', 'Type',\n",
    "                                                             'Batch', and 'Faculty' columns.\n",
    "        department (str): The name of the department (e.g., \"Computer Engineering\").\n",
    "        college (str, optional): The name of the college. Defaults to \"LDRP-ITR\".\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: A nested dictionary containing the organized timetable data.\n",
    "                        Example structure:\n",
    "                        {\n",
    "                            'LDRP-ITR': {\n",
    "                                'Computer Engineering': {\n",
    "                                    '5': {\n",
    "                                        'A': {\n",
    "                                            'AJP': {\n",
    "                                                'lectures': {'designated_faculty': 'FacultyX'},\n",
    "                                                'labs': {'1': {'designated_faculty': 'FacultyY'}}\n",
    "                                            },\n",
    "                                            'CN': { ... }\n",
    "                                        },\n",
    "                                        'B': { ... }\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "    \"\"\"\n",
    "    # Initialize the main dictionary structure with college and department.\n",
    "    final_consolidated_data: Dict[str, Any] = {\n",
    "        college: {\n",
    "            department: {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Iterate through each condensed division timetable.\n",
    "    for division_key, data_frame in condensed_division_tables.items():\n",
    "        # Extract semester and division from the division_key (e.g., \"5A\" -> semester \"5\", division \"A\").\n",
    "        # Assuming division_key format is always <semester_digit><division_letter(s)>.\n",
    "        semester_str = division_key[0] # First character is the semester as a string.\n",
    "        division_str = division_key[1:] # Rest of the string is the division.\n",
    "        \n",
    "        # Initialize semester entry if it doesn't exist within the department.\n",
    "        if semester_str not in final_consolidated_data[college][department]:\n",
    "            final_consolidated_data[college][department][semester_str] = {}\n",
    "            \n",
    "        # Initialize division entry if it doesn't exist within the semester.\n",
    "        if division_str not in final_consolidated_data[college][department][semester_str]:\n",
    "            final_consolidated_data[college][department][semester_str][division_str] = {}\n",
    "            \n",
    "        # Process each unique subject within the current division's DataFrame.\n",
    "        # Using groupby('Subject') is efficient for processing subjects, as it groups\n",
    "        # all rows pertaining to a single subject together.\n",
    "        for subject_code, subject_data_group in data_frame.groupby('Subject'):\n",
    "            subject_details: Dict[str, Any] = {\n",
    "                'lectures': {},\n",
    "                'labs': {}\n",
    "            }\n",
    "            \n",
    "            # Process lectures for the current subject.\n",
    "            lectures_df = subject_data_group[subject_data_group['Type'] == 'Lecture']\n",
    "            if not lectures_df.empty:\n",
    "                # Assuming one designated faculty for lectures per subject per division.\n",
    "                # .iloc[0] picks the first faculty if multiple are listed (due to prior sorting).\n",
    "                subject_details['lectures'] = {\n",
    "                    'designated_faculty': lectures_df['Faculty'].iloc[0]\n",
    "                }\n",
    "            \n",
    "            # Process labs for the current subject.\n",
    "            labs_df = subject_data_group[subject_data_group['Type'] == 'Lab']\n",
    "            if not labs_df.empty:\n",
    "                # For labs, associate each batch with its designated faculty.\n",
    "                # The 'Batch' column from the condensed DataFrame is used as the key.\n",
    "                subject_details['labs'] = {\n",
    "                    str(batch): {'designated_faculty': faculty} # Ensure batch is string for dictionary key.\n",
    "                    for batch, faculty in zip(labs_df['Batch'], labs_df['Faculty'])\n",
    "                }\n",
    "            \n",
    "            # Assign the processed subject data to the final hierarchical dictionary structure.\n",
    "            final_consolidated_data[college][department][semester_str][division_str][subject_code] = subject_details\n",
    "            \n",
    "    return final_consolidated_data\n",
    "\n",
    "def run_matrix_pipeline(matrix_file_path: str, faculty_abbreviations: Set[str], subject_abbreviations: Set[str], department: str, college: str = \"LDRP-ITR\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Orchestrates the entire timetable processing pipeline to generate a final\n",
    "    hierarchical dictionary of consolidated timetable information.\n",
    "\n",
    "    This function calls a sequence of sub-functions to:\n",
    "    1. Load and process Excel data into faculty-wise schedules.\n",
    "    2. Transform faculty schedules into division-wise detailed timetables.\n",
    "    3. Condense division timetables by removing time-slot and day information.\n",
    "    4. Structure the condensed data into a final hierarchical dictionary.\n",
    "\n",
    "    Args:\n",
    "        matrix_file_path (str): The path to the Excel file containing timetable data.\n",
    "        faculty_abbreviations (Set[str]): A set of valid faculty abbreviations.\n",
    "        subject_abbreviations (Set[str]): A set of valid subject abbreviations.\n",
    "        department (str): The name of the department (e.g., \"Computer Engineering\").\n",
    "        college (str, optional): The name of the college. Defaults to \"LDRP-ITR\".\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: A nested dictionary containing the organized timetable data\n",
    "                        grouped by college, department, semester, division, and subject.\n",
    "                        Returns an empty dictionary if any step in the pipeline fails\n",
    "                        to produce valid data.\n",
    "    \"\"\"\n",
    "    print(\"Step 1: Generating full faculty schedules...\")\n",
    "    # Generate the full consolidated faculty schedules from the Excel file.\n",
    "    # This includes initial data cleaning and subject parsing.\n",
    "    all_faculty_schedules = process_all_timetables(\n",
    "        matrix_file_path,\n",
    "        faculties=faculty_abbreviations,\n",
    "        subjects=subject_abbreviations\n",
    "    )\n",
    "    \n",
    "    if not all_faculty_schedules:\n",
    "        print(\"Error: No faculty schedules generated. Aborting.\")\n",
    "        return {}\n",
    "\n",
    "    print(\"Step 2: Creating division-specific timetables...\")\n",
    "    # Create detailed timetable DataFrames for each class division.\n",
    "    # This expands 'ALL' divisions and formats lab time slots.\n",
    "    division_tables = generate_class_schedules(all_faculty_schedules)\n",
    "    \n",
    "    if not division_tables:\n",
    "        print(\"Error: No division timetables created. Aborting.\")\n",
    "        return {}\n",
    "\n",
    "    print(\"Step 3: Condensing division timetables...\")\n",
    "    # Create condensed tables for each division by removing time and day information,\n",
    "    # and dropping duplicate subject entries.\n",
    "    condensed_division_tables = get_division_course_catalog(division_tables)\n",
    "    \n",
    "    if not condensed_division_tables:\n",
    "        print(\"Error: No condensed division timetables created. Aborting.\")\n",
    "        return {}\n",
    "\n",
    "    print(\"Step 4: Creating final hierarchical dictionary...\")\n",
    "    # Create the final hierarchical dictionary structure from the condensed tables.\n",
    "    final_dict = build_hierarchical_schedule(\n",
    "        condensed_division_tables,\n",
    "        department=department,\n",
    "        college=college\n",
    "    )\n",
    "    \n",
    "    print(\"Pipeline complete.\")\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9087200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Generating full faculty schedules...\n",
      "Processing sheet: 1\n",
      "Processing sheet: 2\n",
      "Processing sheet: 3\n",
      "Processing sheet: 4\n",
      "Processing sheet: Sheet1\n",
      "Warning: 'SLOT' not found in the second column of sheet 'Sheet1'. Returning empty DataFrame.\n",
      "Skipping sheet 'Sheet1' due to empty or invalid data.\n",
      "Step 2: Creating division-specific timetables...\n",
      "Step 3: Condensing division timetables...\n",
      "Step 4: Creating final hierarchical dictionary...\n",
      "Pipeline complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LDRP-ITR': {'CE': {'5': {'A': {'AJP': {'lectures': {'designated_faculty': 'AVD'},\n",
       "      'labs': {'1': {'designated_faculty': 'AVD'},\n",
       "       '2': {'designated_faculty': 'AVD'}}},\n",
       "     'CN': {'lectures': {'designated_faculty': 'AP'},\n",
       "      'labs': {'1': {'designated_faculty': 'AP'},\n",
       "       '2': {'designated_faculty': 'AP'},\n",
       "       '3': {'designated_faculty': 'AP'}}},\n",
       "     'DAA': {'lectures': {'designated_faculty': 'AA'},\n",
       "      'labs': {'1': {'designated_faculty': 'AA'},\n",
       "       '2': {'designated_faculty': 'AA'},\n",
       "       '3': {'designated_faculty': 'AA'}}},\n",
       "     'DNET': {'lectures': {'designated_faculty': 'NVP'},\n",
       "      'labs': {'3': {'designated_faculty': 'NVP'}}},\n",
       "     'MP': {'lectures': {'designated_faculty': 'HMB'},\n",
       "      'labs': {'1': {'designated_faculty': 'HMB'},\n",
       "       '2': {'designated_faculty': 'HMB'},\n",
       "       '3': {'designated_faculty': 'HMB'}}},\n",
       "     'OT': {'lectures': {'designated_faculty': 'HCP'},\n",
       "      'labs': {'3': {'designated_faculty': 'HCP'}}},\n",
       "     'SE': {'lectures': {'designated_faculty': 'ABP'},\n",
       "      'labs': {'1': {'designated_faculty': 'ABP'},\n",
       "       '2': {'designated_faculty': 'ABP'},\n",
       "       '3': {'designated_faculty': 'ABP'}}},\n",
       "     'TOC': {'lectures': {'designated_faculty': 'PKP'}, 'labs': {}}},\n",
       "    'B': {'AJP': {'lectures': {'designated_faculty': 'VB'},\n",
       "      'labs': {'1': {'designated_faculty': 'VB'},\n",
       "       '2': {'designated_faculty': 'VB'}}},\n",
       "     'CN': {'lectures': {'designated_faculty': 'MNC'},\n",
       "      'labs': {'1': {'designated_faculty': 'MNC'},\n",
       "       '2': {'designated_faculty': 'MNC'},\n",
       "       '3': {'designated_faculty': 'MNC'}}},\n",
       "     'DAA': {'lectures': {'designated_faculty': 'DT'},\n",
       "      'labs': {'1': {'designated_faculty': 'DT'},\n",
       "       '2': {'designated_faculty': 'DT'},\n",
       "       '3': {'designated_faculty': 'DT'}}},\n",
       "     'DNET': {'lectures': {'designated_faculty': 'NVP'},\n",
       "      'labs': {'3': {'designated_faculty': 'NVP'}}},\n",
       "     'MP': {'lectures': {'designated_faculty': 'NPC'},\n",
       "      'labs': {'1': {'designated_faculty': 'NPC'},\n",
       "       '2': {'designated_faculty': 'NPC'},\n",
       "       '3': {'designated_faculty': 'NPC'}}},\n",
       "     'OT': {'lectures': {'designated_faculty': 'HCP'},\n",
       "      'labs': {'3': {'designated_faculty': 'HCP'}}},\n",
       "     'SE': {'lectures': {'designated_faculty': 'AJD'},\n",
       "      'labs': {'1': {'designated_faculty': 'AJD'},\n",
       "       '2': {'designated_faculty': 'AJD'},\n",
       "       '3': {'designated_faculty': 'AJD'}}},\n",
       "     'TOC': {'lectures': {'designated_faculty': 'HPS'}, 'labs': {}}},\n",
       "    'C': {'AJP': {'lectures': {'designated_faculty': 'TP'},\n",
       "      'labs': {'1': {'designated_faculty': 'TP'},\n",
       "       '2': {'designated_faculty': 'TP'}}},\n",
       "     'CN': {'lectures': {'designated_faculty': 'HJP'},\n",
       "      'labs': {'1': {'designated_faculty': 'HJP'},\n",
       "       '2': {'designated_faculty': 'HJP'},\n",
       "       '3': {'designated_faculty': 'HJP'}}},\n",
       "     'DAA': {'lectures': {'designated_faculty': 'VP'},\n",
       "      'labs': {'1': {'designated_faculty': 'VP'},\n",
       "       '2': {'designated_faculty': 'VP'},\n",
       "       '3': {'designated_faculty': 'VP'}}},\n",
       "     'DNET': {'lectures': {'designated_faculty': 'NVP'},\n",
       "      'labs': {'3': {'designated_faculty': 'NVP'}}},\n",
       "     'MP': {'lectures': {'designated_faculty': 'RW'},\n",
       "      'labs': {'1': {'designated_faculty': 'RW'},\n",
       "       '2': {'designated_faculty': 'RW'},\n",
       "       '3': {'designated_faculty': 'BP'}}},\n",
       "     'OT': {'lectures': {'designated_faculty': 'HCP'},\n",
       "      'labs': {'3': {'designated_faculty': 'HCP'}}},\n",
       "     'SE': {'lectures': {'designated_faculty': 'RSG'},\n",
       "      'labs': {'1': {'designated_faculty': 'RSG'},\n",
       "       '2': {'designated_faculty': 'RSG'},\n",
       "       '3': {'designated_faculty': 'RSG'}}},\n",
       "     'TOC': {'lectures': {'designated_faculty': 'AMP'}, 'labs': {}}},\n",
       "    'D': {'CN': {'lectures': {'designated_faculty': 'HMB'},\n",
       "      'labs': {'1': {'designated_faculty': 'HMB'},\n",
       "       '2': {'designated_faculty': 'HMB'},\n",
       "       '3': {'designated_faculty': 'HMB'}}},\n",
       "     'DAA': {'lectures': {'designated_faculty': 'KV'},\n",
       "      'labs': {'1': {'designated_faculty': 'KV'},\n",
       "       '2': {'designated_faculty': 'KV'},\n",
       "       '3': {'designated_faculty': 'KV'}}},\n",
       "     'DNET': {'lectures': {'designated_faculty': 'NVP'},\n",
       "      'labs': {'3': {'designated_faculty': 'NVP'}}},\n",
       "     'MP': {'lectures': {'designated_faculty': 'BP'},\n",
       "      'labs': {'1': {'designated_faculty': 'BP'},\n",
       "       '2': {'designated_faculty': 'BP'},\n",
       "       '3': {'designated_faculty': 'BP'}}},\n",
       "     'OT': {'lectures': {'designated_faculty': 'HCP'},\n",
       "      'labs': {'3': {'designated_faculty': 'HCP'}}},\n",
       "     'SE': {'lectures': {'designated_faculty': 'JJK'},\n",
       "      'labs': {'1': {'designated_faculty': 'JJK'},\n",
       "       '2': {'designated_faculty': 'JJK'},\n",
       "       '3': {'designated_faculty': 'JJK'}}},\n",
       "     'TOC': {'lectures': {'designated_faculty': 'AHS'}, 'labs': {}}},\n",
       "    'E': {'AJP': {'lectures': {'designated_faculty': 'JCK'},\n",
       "      'labs': {'1': {'designated_faculty': 'JCK'},\n",
       "       '2': {'designated_faculty': 'JCK'}}},\n",
       "     'CN': {'lectures': {'designated_faculty': 'PM'},\n",
       "      'labs': {'1': {'designated_faculty': 'PM'},\n",
       "       '2': {'designated_faculty': 'PM'},\n",
       "       '3': {'designated_faculty': 'PM'}}},\n",
       "     'DAA': {'lectures': {'designated_faculty': 'KR'},\n",
       "      'labs': {'1': {'designated_faculty': 'KR'},\n",
       "       '2': {'designated_faculty': 'KR'},\n",
       "       '3': {'designated_faculty': 'KR'}}},\n",
       "     'DNET': {'lectures': {'designated_faculty': 'NVP'},\n",
       "      'labs': {'3': {'designated_faculty': 'NVP'}}},\n",
       "     'MP': {'lectures': {'designated_faculty': 'RKS'},\n",
       "      'labs': {'1': {'designated_faculty': 'RKS'},\n",
       "       '2': {'designated_faculty': 'RKS'},\n",
       "       '3': {'designated_faculty': 'OP'}}},\n",
       "     'OT': {'lectures': {'designated_faculty': 'HCP'},\n",
       "      'labs': {'3': {'designated_faculty': 'HCP'}}},\n",
       "     'SE': {'lectures': {'designated_faculty': 'VMP'},\n",
       "      'labs': {'2': {'designated_faculty': 'VMP'},\n",
       "       '3': {'designated_faculty': 'VMP'}}},\n",
       "     'TOC': {'lectures': {'designated_faculty': 'SCP'}, 'labs': {}}},\n",
       "    'F': {'AJP': {'lectures': {'designated_faculty': 'TP'},\n",
       "      'labs': {'1': {'designated_faculty': 'TP'},\n",
       "       '2': {'designated_faculty': 'JCK'}}},\n",
       "     'CN': {'lectures': {'designated_faculty': 'TNG'},\n",
       "      'labs': {'1': {'designated_faculty': 'TNG'},\n",
       "       '2': {'designated_faculty': 'TNG'},\n",
       "       '3': {'designated_faculty': 'TNG'}}},\n",
       "     'DAA': {'lectures': {'designated_faculty': 'JJP'},\n",
       "      'labs': {'1': {'designated_faculty': 'JJP'},\n",
       "       '2': {'designated_faculty': 'JJP'},\n",
       "       '3': {'designated_faculty': 'JJP'}}},\n",
       "     'DNET': {'lectures': {'designated_faculty': 'NVP'},\n",
       "      'labs': {'3': {'designated_faculty': 'NVP'}}},\n",
       "     'MP': {'lectures': {'designated_faculty': 'AHS'},\n",
       "      'labs': {'1': {'designated_faculty': 'AHS'},\n",
       "       '2': {'designated_faculty': 'AHS'},\n",
       "       '3': {'designated_faculty': 'AHS'}}},\n",
       "     'OT': {'lectures': {'designated_faculty': 'HCP'},\n",
       "      'labs': {'3': {'designated_faculty': 'HCP'}}},\n",
       "     'SE': {'lectures': {'designated_faculty': 'AP'},\n",
       "      'labs': {'1': {'designated_faculty': 'AP'},\n",
       "       '2': {'designated_faculty': 'AP'},\n",
       "       '3': {'designated_faculty': 'AP'}}},\n",
       "     'TOC': {'lectures': {'designated_faculty': 'OP'}, 'labs': {}}},\n",
       "    'G': {'AJP': {'lectures': {'designated_faculty': 'AVD'},\n",
       "      'labs': {'1': {'designated_faculty': 'AVD'},\n",
       "       '2': {'designated_faculty': 'VB'}}},\n",
       "     'CN': {'lectures': {'designated_faculty': 'KRK'},\n",
       "      'labs': {'1': {'designated_faculty': 'KRK'},\n",
       "       '2': {'designated_faculty': 'KRK'},\n",
       "       '3': {'designated_faculty': 'KRK'}}},\n",
       "     'DAA': {'lectures': {'designated_faculty': 'MV'},\n",
       "      'labs': {'1': {'designated_faculty': 'MV'},\n",
       "       '2': {'designated_faculty': 'MV'},\n",
       "       '3': {'designated_faculty': 'MV'}}},\n",
       "     'DNET': {'lectures': {'designated_faculty': 'NVP'},\n",
       "      'labs': {'3': {'designated_faculty': 'NVP'}}},\n",
       "     'MP': {'lectures': {'designated_faculty': 'HJP'},\n",
       "      'labs': {'1': {'designated_faculty': 'HJP'},\n",
       "       '2': {'designated_faculty': 'HJP'},\n",
       "       '3': {'designated_faculty': 'HJP'}}},\n",
       "     'OT': {'lectures': {'designated_faculty': 'HCP'},\n",
       "      'labs': {'3': {'designated_faculty': 'HCP'}}},\n",
       "     'SE': {'lectures': {'designated_faculty': 'PDN'},\n",
       "      'labs': {'1': {'designated_faculty': 'PDN'},\n",
       "       '2': {'designated_faculty': 'PDN'},\n",
       "       '3': {'designated_faculty': 'PDN'}}},\n",
       "     'TOC': {'lectures': {'designated_faculty': 'BBP'}, 'labs': {}}}},\n",
       "   '7': {'B': {'BT': {'lectures': {'designated_faculty': 'OP'},\n",
       "      'labs': {'1': {'designated_faculty': 'OP'},\n",
       "       '2': {'designated_faculty': 'OP'}}},\n",
       "     'CD': {'lectures': {'designated_faculty': 'AMP'},\n",
       "      'labs': {'1*': {'designated_faculty': 'AMP'},\n",
       "       '2*': {'designated_faculty': 'AMP'},\n",
       "       '3*': {'designated_faculty': 'AMP'}}},\n",
       "     'CS': {'lectures': {'designated_faculty': 'PM'},\n",
       "      'labs': {'1': {'designated_faculty': 'PM'},\n",
       "       '2': {'designated_faculty': 'PM'},\n",
       "       '3': {'designated_faculty': 'PM'}}},\n",
       "     'DS': {'lectures': {'designated_faculty': 'NVP'},\n",
       "      'labs': {'1*': {'designated_faculty': 'NVP'},\n",
       "       '2*': {'designated_faculty': 'NVP'}}},\n",
       "     'IP': {'lectures': {'designated_faculty': 'DT'},\n",
       "      'labs': {'3*': {'designated_faculty': 'DT'}}}},\n",
       "    'D': {'BT': {'lectures': {'designated_faculty': 'TNG'},\n",
       "      'labs': {'1': {'designated_faculty': 'TNG'},\n",
       "       '2': {'designated_faculty': 'TNG'}}},\n",
       "     'CD': {'lectures': {'designated_faculty': 'PKP'},\n",
       "      'labs': {'1*': {'designated_faculty': 'PKP'},\n",
       "       '2*': {'designated_faculty': 'PKP'},\n",
       "       '3*': {'designated_faculty': 'PKP'}}},\n",
       "     'CS': {'lectures': {'designated_faculty': 'VP'},\n",
       "      'labs': {'1': {'designated_faculty': 'VP'},\n",
       "       '2': {'designated_faculty': 'VP'},\n",
       "       '3': {'designated_faculty': 'VP'}}},\n",
       "     'DS': {'lectures': {'designated_faculty': 'NVP'},\n",
       "      'labs': {'1*': {'designated_faculty': 'NVP'},\n",
       "       '2*': {'designated_faculty': 'JCK'}}},\n",
       "     'IP': {'lectures': {'designated_faculty': 'DT'},\n",
       "      'labs': {'3*': {'designated_faculty': 'DT'}}}},\n",
       "    'E': {'BT': {'lectures': {'designated_faculty': 'TP'},\n",
       "      'labs': {'1': {'designated_faculty': 'TP'},\n",
       "       '2': {'designated_faculty': 'TP'}}},\n",
       "     'CD': {'lectures': {'designated_faculty': 'AA'},\n",
       "      'labs': {'1*': {'designated_faculty': 'AA'},\n",
       "       '2*': {'designated_faculty': 'AA'},\n",
       "       '3*': {'designated_faculty': 'AA'}}},\n",
       "     'CS': {'lectures': {'designated_faculty': 'AJD'},\n",
       "      'labs': {'1': {'designated_faculty': 'AJD'},\n",
       "       '2': {'designated_faculty': 'AJD'},\n",
       "       '3': {'designated_faculty': 'AJD'}}},\n",
       "     'DS': {'lectures': {'designated_faculty': 'VMP'},\n",
       "      'labs': {'1*': {'designated_faculty': 'VMP'},\n",
       "       '2*': {'designated_faculty': 'VMP'}}},\n",
       "     'IP': {'lectures': {'designated_faculty': 'HCP'},\n",
       "      'labs': {'3*': {'designated_faculty': 'HCP'}}},\n",
       "     'NLP': {'lectures': {'designated_faculty': 'RW'},\n",
       "      'labs': {'3': {'designated_faculty': 'RW'}}}},\n",
       "    'K': {'BT': {'lectures': {'designated_faculty': 'VB'},\n",
       "      'labs': {'1': {'designated_faculty': 'VB'},\n",
       "       '2': {'designated_faculty': 'VB'}}},\n",
       "     'CD': {'lectures': {'designated_faculty': 'MV'},\n",
       "      'labs': {'1*': {'designated_faculty': 'MV'},\n",
       "       '2*': {'designated_faculty': 'MV'},\n",
       "       '3*': {'designated_faculty': 'MV'}}},\n",
       "     'CS': {'lectures': {'designated_faculty': 'JJK'},\n",
       "      'labs': {'1': {'designated_faculty': 'JJK'},\n",
       "       '2': {'designated_faculty': 'JJK'},\n",
       "       '3': {'designated_faculty': 'JJK'}}},\n",
       "     'DS': {'lectures': {'designated_faculty': 'VMP'},\n",
       "      'labs': {'1*': {'designated_faculty': 'VMP'},\n",
       "       '2*': {'designated_faculty': 'VMP'}}},\n",
       "     'IP': {'lectures': {'designated_faculty': 'HCP'},\n",
       "      'labs': {'3*': {'designated_faculty': 'HCP'}}},\n",
       "     'NLP': {'lectures': {'designated_faculty': 'RW'},\n",
       "      'labs': {'3': {'designated_faculty': 'RW'}}}},\n",
       "    'b': {'BT': {'lectures': {'designated_faculty': 'TP'},\n",
       "      'labs': {'1': {'designated_faculty': 'OP'},\n",
       "       '2': {'designated_faculty': 'TNG'}}},\n",
       "     'CD': {'lectures': {'designated_faculty': 'KR'},\n",
       "      'labs': {'1*': {'designated_faculty': 'KR'},\n",
       "       '2*': {'designated_faculty': 'KR'},\n",
       "       '3*': {'designated_faculty': 'KR'}}},\n",
       "     'CS': {'lectures': {'designated_faculty': 'RSG'},\n",
       "      'labs': {'1': {'designated_faculty': 'RSG'},\n",
       "       '2': {'designated_faculty': 'RSG'},\n",
       "       '3': {'designated_faculty': 'RSG'}}},\n",
       "     'DS': {'lectures': {'designated_faculty': 'JCK'},\n",
       "      'labs': {'1*': {'designated_faculty': 'JCK'},\n",
       "       '2*': {'designated_faculty': 'JCK'}}},\n",
       "     'IP': {'lectures': {'designated_faculty': 'HCP'},\n",
       "      'labs': {'3*': {'designated_faculty': 'HCP'}}},\n",
       "     'NLP': {'lectures': {'designated_faculty': 'RW'},\n",
       "      'labs': {'3': {'designated_faculty': 'RW'}}}},\n",
       "    'IT': {'IP': {'lectures': {'designated_faculty': 'DT'}, 'labs': {}}},\n",
       "    'I': {'IP': {'lectures': {},\n",
       "      'labs': {'3*': {'designated_faculty': 'DT'}}}}},\n",
       "   '3': {'B': {'DBMS': {'lectures': {'designated_faculty': 'RKS'},\n",
       "      'labs': {'1': {'designated_faculty': 'RKS'},\n",
       "       '2': {'designated_faculty': 'AJD'},\n",
       "       '3': {'designated_faculty': 'RKS'}}},\n",
       "     'DSA': {'lectures': {'designated_faculty': 'JJP'},\n",
       "      'labs': {'1': {'designated_faculty': 'JJP'},\n",
       "       '2': {'designated_faculty': 'JJP'},\n",
       "       '3': {'designated_faculty': 'JJP'}}},\n",
       "     'ITW': {'lectures': {'designated_faculty': 'SMC'},\n",
       "      'labs': {'1': {'designated_faculty': 'KP'},\n",
       "       '2': {'designated_faculty': 'JCK'},\n",
       "       '3': {'designated_faculty': 'SMC'}}}},\n",
       "    'P': {'DBMS': {'lectures': {},\n",
       "      'labs': {'1': {'designated_faculty': 'MV'},\n",
       "       '3': {'designated_faculty': 'TNG'}}},\n",
       "     'DSA': {'lectures': {'designated_faculty': 'BZ'},\n",
       "      'labs': {'1': {'designated_faculty': 'JJK'},\n",
       "       '2': {'designated_faculty': 'BZ'},\n",
       "       '3': {'designated_faculty': 'BZ'}}},\n",
       "     'ITW': {'lectures': {'designated_faculty': 'NPC'},\n",
       "      'labs': {'1': {'designated_faculty': 'DT'},\n",
       "       '2': {'designated_faculty': 'SMC'},\n",
       "       '3': {'designated_faculty': 'NPC'}}}},\n",
       "    'F': {'DBMS': {'lectures': {'designated_faculty': 'HPS'},\n",
       "      'labs': {'-': {'designated_faculty': 'HPS'},\n",
       "       '1': {'designated_faculty': 'HPS'},\n",
       "       '2': {'designated_faculty': 'HPS'},\n",
       "       '3': {'designated_faculty': 'SCP'}}},\n",
       "     'DSA': {'lectures': {'designated_faculty': 'HT'},\n",
       "      'labs': {'1': {'designated_faculty': 'AA'},\n",
       "       '2': {'designated_faculty': 'PKP'},\n",
       "       '3': {'designated_faculty': 'PKP'}}},\n",
       "     'ITW': {'lectures': {'designated_faculty': 'MNC'},\n",
       "      'labs': {'1': {'designated_faculty': 'MNC'},\n",
       "       '2': {'designated_faculty': 'AP'},\n",
       "       '3': {'designated_faculty': 'MNC'}}}},\n",
       "    'G': {'DBMS': {'lectures': {'designated_faculty': 'JHG'},\n",
       "      'labs': {'1': {'designated_faculty': 'KP'},\n",
       "       '2': {'designated_faculty': 'RMM'},\n",
       "       '3': {'designated_faculty': 'RSG'}}},\n",
       "     'DSA': {'lectures': {'designated_faculty': 'SCP'},\n",
       "      'labs': {'1': {'designated_faculty': 'SCP'},\n",
       "       '2': {'designated_faculty': 'SCP'},\n",
       "       '3': {'designated_faculty': 'SCP'}}},\n",
       "     'ITW': {'lectures': {'designated_faculty': 'BBP'},\n",
       "      'labs': {'1': {'designated_faculty': 'BBP'},\n",
       "       '2': {'designated_faculty': 'BBP'},\n",
       "       '3': {'designated_faculty': 'BBP'}}}},\n",
       "    'Q': {'DBMS': {'lectures': {'designated_faculty': 'KV'},\n",
       "      'labs': {'1': {'designated_faculty': 'KV'},\n",
       "       '2': {'designated_faculty': 'KV'},\n",
       "       '3': {'designated_faculty': 'KV'}}},\n",
       "     'ITW': {'lectures': {'designated_faculty': 'RMM'},\n",
       "      'labs': {'1': {'designated_faculty': 'SMC'},\n",
       "       '2': {'designated_faculty': 'BBP'},\n",
       "       '3': {'designated_faculty': 'VP'}}}},\n",
       "    'C': {'DBMS': {'lectures': {'designated_faculty': 'BZ'},\n",
       "      'labs': {'-': {'designated_faculty': 'BZ'},\n",
       "       '1': {'designated_faculty': 'SCP'},\n",
       "       '2': {'designated_faculty': 'NPC'},\n",
       "       '3': {'designated_faculty': 'BZ'}}},\n",
       "     'DSA': {'lectures': {'designated_faculty': 'KP'},\n",
       "      'labs': {'1': {'designated_faculty': 'PKP'},\n",
       "       '2': {'designated_faculty': 'PKP'}}},\n",
       "     'ITW': {'lectures': {},\n",
       "      'labs': {'1': {'designated_faculty': 'VB'},\n",
       "       '2': {'designated_faculty': 'TP'},\n",
       "       '3': {'designated_faculty': 'MNC'}}}},\n",
       "    'D': {'DBMS': {'lectures': {'designated_faculty': 'KP'},\n",
       "      'labs': {'1': {'designated_faculty': 'KP'},\n",
       "       '2': {'designated_faculty': 'OP'},\n",
       "       '3': {'designated_faculty': 'KP'}}},\n",
       "     'DSA': {'lectures': {'designated_faculty': 'JHG'},\n",
       "      'labs': {'1': {'designated_faculty': 'AHS'},\n",
       "       '2': {'designated_faculty': 'AHS'},\n",
       "       '3': {'designated_faculty': 'AHS'}}},\n",
       "     'ITW': {'lectures': {'designated_faculty': 'PDN'},\n",
       "      'labs': {'1': {'designated_faculty': 'PDN'},\n",
       "       '2': {'designated_faculty': 'PDN'},\n",
       "       '3': {'designated_faculty': 'PDN'}}}},\n",
       "    'E': {'DBMS': {'lectures': {'designated_faculty': 'KRK'},\n",
       "      'labs': {'1': {'designated_faculty': 'KRK'},\n",
       "       '2': {'designated_faculty': 'KRK'},\n",
       "       '3': {'designated_faculty': 'RW'}}},\n",
       "     'DSA': {'lectures': {'designated_faculty': 'SMC'},\n",
       "      'labs': {'2': {'designated_faculty': 'JJP'},\n",
       "       '3': {'designated_faculty': 'SMC'}}},\n",
       "     'ITW': {'lectures': {},\n",
       "      'labs': {'1': {'designated_faculty': 'RMM'},\n",
       "       '2': {'designated_faculty': 'AVD'},\n",
       "       '3': {'designated_faculty': 'AMP'}}},\n",
       "     'SE': {'lectures': {}, 'labs': {'1': {'designated_faculty': 'VMP'}}}},\n",
       "    'A': {'DBMS': {'lectures': {'designated_faculty': 'BP'},\n",
       "      'labs': {'1': {'designated_faculty': 'BP'},\n",
       "       '2': {'designated_faculty': 'HPS'},\n",
       "       '3': {'designated_faculty': 'BP'}}},\n",
       "     'DSA': {'lectures': {'designated_faculty': 'HT'},\n",
       "      'labs': {'1': {'designated_faculty': 'AHS'},\n",
       "       '3': {'designated_faculty': 'BZ'}}},\n",
       "     'ITW': {'lectures': {'designated_faculty': 'AVD'},\n",
       "      'labs': {'1': {'designated_faculty': 'AVD'},\n",
       "       '2': {'designated_faculty': 'AVD'},\n",
       "       '3': {'designated_faculty': 'AVD'}}}}},\n",
       "   '1': {'P': {'FOP': {'lectures': {'designated_faculty': 'RMM'},\n",
       "      'labs': {'1': {'designated_faculty': 'JHG'},\n",
       "       '2': {'designated_faculty': 'RKS'},\n",
       "       '3': {'designated_faculty': 'RMM'}}}},\n",
       "    'Q': {'FOP': {'lectures': {'designated_faculty': 'RMM'},\n",
       "      'labs': {'1': {'designated_faculty': 'RMM'},\n",
       "       '2': {'designated_faculty': 'JHG'},\n",
       "       '3': {'designated_faculty': 'JHG'}}}}}}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = run_matrix_pipeline(matrix_file_path, faculty_abbreviations, subject_abbreviations, department=\"CE\", college=\"LDRP-ITR\")\n",
    "dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".reflectify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
